{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akashtc/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import dataset67.65\n",
    "user_df = pd.read_csv('data/User_SongFeatures_data.csv', compression=\"xz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our model we will randomly split the dataset into three. There will be two test data sets and one validation dataset. The first data set will be used to perform matrix factorization to extract user and item latent factors. The second dataset will be used to train our classification model. And lastly, our validation set will be used to evaluate our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3372"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split into train, train 2 and validation set\n",
    "# make sure users who have only listened once is in train set\n",
    "\n",
    "song_count = user_df.groupby('user_id').count()[['song_id']].reset_index()\n",
    "one_timers = song_count[song_count['song_id'] == 1]\n",
    "len(one_timers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset data of users who only listened one time\n",
    "one_df = user_df[user_df.user_id.isin(one_timers.user_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1137044"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subset rest of data\n",
    "df = user_df[~user_df.user_id.isin(one_timers.user_id)]\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('listen_count', axis=1)\n",
    "y = df.listen_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.4, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "409335\n",
      "454818\n",
      "272891\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(X_test))\n",
    "print(len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/km/dzl8bwrn3sv4v9_tbyy93vn4009q8p/T/ipykernel_17880/1307692615.py:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train1 = X_train.join(y_train).append(one_df, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "train1 = X_train.join(y_train).append(one_df, ignore_index=True)\n",
    "train2 = X_test.join(y_test)\n",
    "val = X_val.join(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412707\n",
      "454818\n",
      "272891\n"
     ]
    }
   ],
   "source": [
    "print(len(train1))\n",
    "print(len(train2))\n",
    "print(len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69327\n",
      "5679\n"
     ]
    }
   ],
   "source": [
    "# since there are songs with multiple ids with have to group by user id and song and sum the listen counts\n",
    "\n",
    "train1_df = train1.groupby(['user_id','song'], as_index=False)['listen_count'].sum()\n",
    "print(train1_df.user_id.nunique())\n",
    "print(train1_df.song.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we perform non negative matrix factorization on our dataset we must first transform it into a matrix with user_id and song and the corresponding listen count. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>song</th>\n",
       "      <th>listen_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00005c6177188f12fb5e2e82cdbd93e8a3f35e64</td>\n",
       "      <td>Ironmasters - The Men They Couldn't Hang</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00030033e3a2f904a48ec1dd53019c9969b6ef1f</td>\n",
       "      <td>Chasing Cars - Snow Patrol</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00030033e3a2f904a48ec1dd53019c9969b6ef1f</td>\n",
       "      <td>You'd Be So Nice To Come Home To - Julie London</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0007235c769e610e3d339a17818a5708e41008d9</td>\n",
       "      <td>Dip It Low - Christina Milian</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0007235c769e610e3d339a17818a5708e41008d9</td>\n",
       "      <td>Su veneno - Aventura</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    user_id  \\\n",
       "0  00005c6177188f12fb5e2e82cdbd93e8a3f35e64   \n",
       "1  00030033e3a2f904a48ec1dd53019c9969b6ef1f   \n",
       "2  00030033e3a2f904a48ec1dd53019c9969b6ef1f   \n",
       "3  0007235c769e610e3d339a17818a5708e41008d9   \n",
       "4  0007235c769e610e3d339a17818a5708e41008d9   \n",
       "\n",
       "                                              song  listen_count  \n",
       "0         Ironmasters - The Men They Couldn't Hang             1  \n",
       "1                       Chasing Cars - Snow Patrol             4  \n",
       "2  You'd Be So Nice To Come Home To - Julie London             1  \n",
       "3                    Dip It Low - Christina Milian             3  \n",
       "4                             Su veneno - Aventura             5  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>song</th>\n",
       "      <th>&amp; Down - Boys Noize</th>\n",
       "      <th>' Cello Song - Nick Drake</th>\n",
       "      <th>'97 Bonnie &amp; Clyde - Eminem</th>\n",
       "      <th>'Round Midnight - Amy Winehouse</th>\n",
       "      <th>(Antichrist Television Blues) - Arcade Fire</th>\n",
       "      <th>(I Just) Died In Your Arms - Cutting Crew</th>\n",
       "      <th>(If You're Wondering If I Want You To) I Want You To - Weezer</th>\n",
       "      <th>(Nice Dream) - Radiohead</th>\n",
       "      <th>(Sittin' On) The Dock Of The Bay - Otis Redding</th>\n",
       "      <th>(The Symphony Of) Blase' - Anberlin</th>\n",
       "      <th>...</th>\n",
       "      <th>and then patterns - Four Tet</th>\n",
       "      <th>clouding - Four Tet</th>\n",
       "      <th>high fives - Four Tet</th>\n",
       "      <th>in white rooms - Booka Shade</th>\n",
       "      <th>mOBSCENE - Marilyn Manson</th>\n",
       "      <th>paranoid android - Christopher O'Riley</th>\n",
       "      <th>smile around the face - Four Tet</th>\n",
       "      <th>sun drums and soil - Four Tet</th>\n",
       "      <th>the Love Song - K-OS</th>\n",
       "      <th>you were there with me - Four Tet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00005c6177188f12fb5e2e82cdbd93e8a3f35e64</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00030033e3a2f904a48ec1dd53019c9969b6ef1f</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0007235c769e610e3d339a17818a5708e41008d9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000a5c8b4d8b2c98f7a205219181d039edcd4506</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000b474f815bcff17a4bc9ce5324f9352dafe07d</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5679 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "song                                      & Down - Boys Noize  \\\n",
       "user_id                                                         \n",
       "00005c6177188f12fb5e2e82cdbd93e8a3f35e64                  0.0   \n",
       "00030033e3a2f904a48ec1dd53019c9969b6ef1f                  0.0   \n",
       "0007235c769e610e3d339a17818a5708e41008d9                  0.0   \n",
       "000a5c8b4d8b2c98f7a205219181d039edcd4506                  0.0   \n",
       "000b474f815bcff17a4bc9ce5324f9352dafe07d                  0.0   \n",
       "\n",
       "song                                      ' Cello Song - Nick Drake  \\\n",
       "user_id                                                               \n",
       "00005c6177188f12fb5e2e82cdbd93e8a3f35e64                        0.0   \n",
       "00030033e3a2f904a48ec1dd53019c9969b6ef1f                        0.0   \n",
       "0007235c769e610e3d339a17818a5708e41008d9                        0.0   \n",
       "000a5c8b4d8b2c98f7a205219181d039edcd4506                        0.0   \n",
       "000b474f815bcff17a4bc9ce5324f9352dafe07d                        0.0   \n",
       "\n",
       "song                                      '97 Bonnie & Clyde - Eminem  \\\n",
       "user_id                                                                 \n",
       "00005c6177188f12fb5e2e82cdbd93e8a3f35e64                          0.0   \n",
       "00030033e3a2f904a48ec1dd53019c9969b6ef1f                          0.0   \n",
       "0007235c769e610e3d339a17818a5708e41008d9                          0.0   \n",
       "000a5c8b4d8b2c98f7a205219181d039edcd4506                          0.0   \n",
       "000b474f815bcff17a4bc9ce5324f9352dafe07d                          0.0   \n",
       "\n",
       "song                                      'Round Midnight - Amy Winehouse  \\\n",
       "user_id                                                                     \n",
       "00005c6177188f12fb5e2e82cdbd93e8a3f35e64                              0.0   \n",
       "00030033e3a2f904a48ec1dd53019c9969b6ef1f                              0.0   \n",
       "0007235c769e610e3d339a17818a5708e41008d9                              0.0   \n",
       "000a5c8b4d8b2c98f7a205219181d039edcd4506                              0.0   \n",
       "000b474f815bcff17a4bc9ce5324f9352dafe07d                              0.0   \n",
       "\n",
       "song                                      (Antichrist Television Blues) - Arcade Fire  \\\n",
       "user_id                                                                                 \n",
       "00005c6177188f12fb5e2e82cdbd93e8a3f35e64                                          0.0   \n",
       "00030033e3a2f904a48ec1dd53019c9969b6ef1f                                          0.0   \n",
       "0007235c769e610e3d339a17818a5708e41008d9                                          0.0   \n",
       "000a5c8b4d8b2c98f7a205219181d039edcd4506                                          0.0   \n",
       "000b474f815bcff17a4bc9ce5324f9352dafe07d                                          0.0   \n",
       "\n",
       "song                                      (I Just) Died In Your Arms - Cutting Crew  \\\n",
       "user_id                                                                               \n",
       "00005c6177188f12fb5e2e82cdbd93e8a3f35e64                                        0.0   \n",
       "00030033e3a2f904a48ec1dd53019c9969b6ef1f                                        0.0   \n",
       "0007235c769e610e3d339a17818a5708e41008d9                                        0.0   \n",
       "000a5c8b4d8b2c98f7a205219181d039edcd4506                                        0.0   \n",
       "000b474f815bcff17a4bc9ce5324f9352dafe07d                                        0.0   \n",
       "\n",
       "song                                      (If You're Wondering If I Want You To) I Want You To - Weezer  \\\n",
       "user_id                                                                                                   \n",
       "00005c6177188f12fb5e2e82cdbd93e8a3f35e64                                                0.0               \n",
       "00030033e3a2f904a48ec1dd53019c9969b6ef1f                                                0.0               \n",
       "0007235c769e610e3d339a17818a5708e41008d9                                                0.0               \n",
       "000a5c8b4d8b2c98f7a205219181d039edcd4506                                                0.0               \n",
       "000b474f815bcff17a4bc9ce5324f9352dafe07d                                                0.0               \n",
       "\n",
       "song                                      (Nice Dream) - Radiohead  \\\n",
       "user_id                                                              \n",
       "00005c6177188f12fb5e2e82cdbd93e8a3f35e64                       0.0   \n",
       "00030033e3a2f904a48ec1dd53019c9969b6ef1f                       0.0   \n",
       "0007235c769e610e3d339a17818a5708e41008d9                       0.0   \n",
       "000a5c8b4d8b2c98f7a205219181d039edcd4506                       0.0   \n",
       "000b474f815bcff17a4bc9ce5324f9352dafe07d                       0.0   \n",
       "\n",
       "song                                      (Sittin' On) The Dock Of The Bay - Otis Redding  \\\n",
       "user_id                                                                                     \n",
       "00005c6177188f12fb5e2e82cdbd93e8a3f35e64                                              0.0   \n",
       "00030033e3a2f904a48ec1dd53019c9969b6ef1f                                              0.0   \n",
       "0007235c769e610e3d339a17818a5708e41008d9                                              0.0   \n",
       "000a5c8b4d8b2c98f7a205219181d039edcd4506                                              0.0   \n",
       "000b474f815bcff17a4bc9ce5324f9352dafe07d                                              0.0   \n",
       "\n",
       "song                                      (The Symphony Of) Blase' - Anberlin  \\\n",
       "user_id                                                                         \n",
       "00005c6177188f12fb5e2e82cdbd93e8a3f35e64                                  0.0   \n",
       "00030033e3a2f904a48ec1dd53019c9969b6ef1f                                  0.0   \n",
       "0007235c769e610e3d339a17818a5708e41008d9                                  0.0   \n",
       "000a5c8b4d8b2c98f7a205219181d039edcd4506                                  0.0   \n",
       "000b474f815bcff17a4bc9ce5324f9352dafe07d                                  0.0   \n",
       "\n",
       "song                                      ...  and then patterns - Four Tet  \\\n",
       "user_id                                   ...                                 \n",
       "00005c6177188f12fb5e2e82cdbd93e8a3f35e64  ...                           0.0   \n",
       "00030033e3a2f904a48ec1dd53019c9969b6ef1f  ...                           0.0   \n",
       "0007235c769e610e3d339a17818a5708e41008d9  ...                           0.0   \n",
       "000a5c8b4d8b2c98f7a205219181d039edcd4506  ...                           0.0   \n",
       "000b474f815bcff17a4bc9ce5324f9352dafe07d  ...                           0.0   \n",
       "\n",
       "song                                      clouding - Four Tet  \\\n",
       "user_id                                                         \n",
       "00005c6177188f12fb5e2e82cdbd93e8a3f35e64                  0.0   \n",
       "00030033e3a2f904a48ec1dd53019c9969b6ef1f                  0.0   \n",
       "0007235c769e610e3d339a17818a5708e41008d9                  0.0   \n",
       "000a5c8b4d8b2c98f7a205219181d039edcd4506                  0.0   \n",
       "000b474f815bcff17a4bc9ce5324f9352dafe07d                  0.0   \n",
       "\n",
       "song                                      high fives - Four Tet  \\\n",
       "user_id                                                           \n",
       "00005c6177188f12fb5e2e82cdbd93e8a3f35e64                    0.0   \n",
       "00030033e3a2f904a48ec1dd53019c9969b6ef1f                    0.0   \n",
       "0007235c769e610e3d339a17818a5708e41008d9                    0.0   \n",
       "000a5c8b4d8b2c98f7a205219181d039edcd4506                    0.0   \n",
       "000b474f815bcff17a4bc9ce5324f9352dafe07d                    0.0   \n",
       "\n",
       "song                                      in white rooms - Booka Shade  \\\n",
       "user_id                                                                  \n",
       "00005c6177188f12fb5e2e82cdbd93e8a3f35e64                           0.0   \n",
       "00030033e3a2f904a48ec1dd53019c9969b6ef1f                           0.0   \n",
       "0007235c769e610e3d339a17818a5708e41008d9                           0.0   \n",
       "000a5c8b4d8b2c98f7a205219181d039edcd4506                           0.0   \n",
       "000b474f815bcff17a4bc9ce5324f9352dafe07d                           0.0   \n",
       "\n",
       "song                                      mOBSCENE - Marilyn Manson  \\\n",
       "user_id                                                               \n",
       "00005c6177188f12fb5e2e82cdbd93e8a3f35e64                        0.0   \n",
       "00030033e3a2f904a48ec1dd53019c9969b6ef1f                        0.0   \n",
       "0007235c769e610e3d339a17818a5708e41008d9                        0.0   \n",
       "000a5c8b4d8b2c98f7a205219181d039edcd4506                        0.0   \n",
       "000b474f815bcff17a4bc9ce5324f9352dafe07d                        0.0   \n",
       "\n",
       "song                                      paranoid android - Christopher O'Riley  \\\n",
       "user_id                                                                            \n",
       "00005c6177188f12fb5e2e82cdbd93e8a3f35e64                                     0.0   \n",
       "00030033e3a2f904a48ec1dd53019c9969b6ef1f                                     0.0   \n",
       "0007235c769e610e3d339a17818a5708e41008d9                                     0.0   \n",
       "000a5c8b4d8b2c98f7a205219181d039edcd4506                                     0.0   \n",
       "000b474f815bcff17a4bc9ce5324f9352dafe07d                                     0.0   \n",
       "\n",
       "song                                      smile around the face - Four Tet  \\\n",
       "user_id                                                                      \n",
       "00005c6177188f12fb5e2e82cdbd93e8a3f35e64                               0.0   \n",
       "00030033e3a2f904a48ec1dd53019c9969b6ef1f                               0.0   \n",
       "0007235c769e610e3d339a17818a5708e41008d9                               0.0   \n",
       "000a5c8b4d8b2c98f7a205219181d039edcd4506                               0.0   \n",
       "000b474f815bcff17a4bc9ce5324f9352dafe07d                               0.0   \n",
       "\n",
       "song                                      sun drums and soil - Four Tet  \\\n",
       "user_id                                                                   \n",
       "00005c6177188f12fb5e2e82cdbd93e8a3f35e64                            0.0   \n",
       "00030033e3a2f904a48ec1dd53019c9969b6ef1f                            0.0   \n",
       "0007235c769e610e3d339a17818a5708e41008d9                            0.0   \n",
       "000a5c8b4d8b2c98f7a205219181d039edcd4506                            0.0   \n",
       "000b474f815bcff17a4bc9ce5324f9352dafe07d                            0.0   \n",
       "\n",
       "song                                      the Love Song - K-OS  \\\n",
       "user_id                                                          \n",
       "00005c6177188f12fb5e2e82cdbd93e8a3f35e64                   0.0   \n",
       "00030033e3a2f904a48ec1dd53019c9969b6ef1f                   0.0   \n",
       "0007235c769e610e3d339a17818a5708e41008d9                   0.0   \n",
       "000a5c8b4d8b2c98f7a205219181d039edcd4506                   0.0   \n",
       "000b474f815bcff17a4bc9ce5324f9352dafe07d                   0.0   \n",
       "\n",
       "song                                      you were there with me - Four Tet  \n",
       "user_id                                                                      \n",
       "00005c6177188f12fb5e2e82cdbd93e8a3f35e64                                0.0  \n",
       "00030033e3a2f904a48ec1dd53019c9969b6ef1f                                0.0  \n",
       "0007235c769e610e3d339a17818a5708e41008d9                                0.0  \n",
       "000a5c8b4d8b2c98f7a205219181d039edcd4506                                0.0  \n",
       "000b474f815bcff17a4bc9ce5324f9352dafe07d                                0.0  \n",
       "\n",
       "[5 rows x 5679 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf_df = train1_df.pivot(index = 'user_id', columns ='song', values = 'listen_count').fillna(0)\n",
    "mf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn into matrix\n",
    "\n",
    "mf_df = mf_df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now perform non negative matrix factorization to extract latent factors from our matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "model = NMF(n_components=10, init='random', random_state=0)\n",
    "W = model.fit_transform(mf_df)\n",
    "H = model.components_\n",
    "\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/57370472/recommendation-system-with-matrix-factorization-for-huge-data-gives-memoryerror"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "user = pd.DataFrame(W, columns = ['u1','u2','u3','u4','u5','u6','u7', 'u8', 'u9', 'u10'])\n",
    "\n",
    "song = pd.DataFrame(H).transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1_df.user_id.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will append the user and song latent factors found to our original dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add latent factors as new columns\n",
    "\n",
    "user_factors = pd.DataFrame(train1_df.user_id.unique()).join(user)\n",
    "user_factors.columns = ['user_id','u1','u2','u3','u4','u5','u6','u7', 'u8', 'u9', 'u10']\n",
    "\n",
    "user_factors.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_factors = pd.DataFrame(train1_df.song.unique(), columns = ['song']).join(song)\n",
    "song_factors.columns = ['song','s1','s2','s3','s4','s5','s6','s7', 's8', 's9', 's10']\n",
    "song_factors.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2_df = pd.merge(train2, user_factors, on='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2_df = pd.merge(train2_df, song_factors, on='song')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train2_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.listen_count.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is a classification problem, we will transform listen_count into labels of 'one' and 'one_plus'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(row):\n",
    "    if  row['listen_count'] == 1:\n",
    "        val = 0\n",
    "    else:\n",
    "        val = 1\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2_df['label'] = train2_df.apply(f, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract relevant columns for classification\n",
    "\n",
    "train2_X = train2_df[['acousticness', 'danceability',\n",
    "       'duration_ms', 'energy', 'instrumentalness', 'key', 'liveness',\n",
    "       'loudness', 'mode', 'speechiness', 'tempo', 'time_signature','valence','s1', 's2', 's3', 's4', 's5', 's6','s7','s8', 's9', 's10', 'u1','u2','u3','u4','u5','u6','u7','u8', 'u9', 'u10']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train2_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract labels\n",
    "train2_y = train2_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge user and song latent factors to validation set\n",
    "\n",
    "val_df = pd.merge(val, user_factors, on='user_id')\n",
    "val_df = pd.merge(val_df, song_factors, on='song')\n",
    "val_df['label'] = val_df.apply(f, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_X = val_df[['acousticness', 'danceability',\n",
    "       'duration_ms', 'energy', 'instrumentalness', 'key', 'liveness',\n",
    "       'loudness', 'mode', 'speechiness', 'tempo', 'time_signature','valence','s1', 's2', 's3', 's4', 's5', 's6','s7','s8', 's9', 's10', 'u1','u2','u3','u4','u5','u6','u7','u8', 'u9', 'u10']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_y = val_df['label']\n",
    "val_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will train XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBOOST TRAINING ACCURACY\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import (classification_report,confusion_matrix, accuracy_score, f1_score, roc_auc_score)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(train2_X, train2_y)\n",
    "xgb_pred = xgb.predict(train2_X)\n",
    "y_pred = xgb.predict_proba(train2_X)[:,1]\n",
    "\n",
    "\n",
    "print('\\n Confusion Matrix:\\n',confusion_matrix(train2_y,xgb_pred))\n",
    "print(\"\\n Classification Report: \\n\", classification_report(train2_y, xgb_pred))\n",
    "print(\"Accuracy:\", (accuracy_score(train2_y,xgb_pred)))\n",
    "print(\"AUC Score:\", (roc_auc_score(train2_y,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost TEST accuracy\n",
    "xgb_pred2 = xgb.predict(val_X)\n",
    "y_pred2 = xgb.predict_proba(val_X)[:,1]\n",
    "\n",
    "print('\\n Confusion Matrix:\\n',confusion_matrix(val_y,xgb_pred2))\n",
    "print(\"\\n Classification Report: \\n\", classification_report(val_y, xgb_pred2))\n",
    "print(\"Accuracy:\", (accuracy_score(val_y,xgb_pred2)))\n",
    "print(\"AUC Score:\", (roc_auc_score(val_y,y_pred2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "import matplotlib.pyplot as plt\n",
    "plot_importance(xgb)\n",
    "plt.figure(figsize=(30,10))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove least important features \n",
    "\n",
    "xgb_f = XGBClassifier()\n",
    "xgb_f.fit(train2_X.drop(['mode','s8', 'time_signature','s6','s2', 's4','s5','s1','key'], axis = 1), train2_y)\n",
    "\n",
    "xgb_pred2 = xgb_f.predict(val_X.drop(['mode','s8', 'time_signature','s6', 's2','s4','s5','s1','key'], axis = 1))\n",
    "y_pred2 = xgb_f.predict_proba(val_X.drop(['mode','s8', 'time_signature', 's6', 's2','s4','s5','s1','key'], axis = 1))[:,1]\n",
    "\n",
    "print('\\n Confusion Matrix:\\n',confusion_matrix(val_y,xgb_pred2))\n",
    "print(\"\\n Classification Report: \\n\", classification_report(val_y, xgb_pred2))\n",
    "print(\"Accuracy:\", (accuracy_score(val_y,xgb_pred2)))\n",
    "print(\"AUC Score:\", (roc_auc_score(val_y,y_pred2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will play with the hyperparameter to see if we can increase AUC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "xgb2 = XGBClassifier(subsample=0.6, colsample_bytree=0.6, max_depth=8, learning_rate=0.01, n_estimators=1000 )\n",
    "xgb2.fit(train2_X.drop(['mode','s8', 'time_signature','s6','s2', 's4','s5','s1','key'], axis = 1), train2_y)\n",
    "xgb_pred3 = xgb2.predict(val_X.drop(['mode','s8', 'time_signature','s6', 's2','s4','s5','s1','key'], axis = 1))\n",
    "y_pred3 = xgb2.predict_proba(val_X.drop(['mode','s8', 'time_signature','s6', 's2','s4','s5','s1','key'], axis = 1))[:,1]\n",
    "\n",
    "\n",
    "print('\\n Confusion Matrix:\\n',confusion_matrix(val_y,xgb_pred3))\n",
    "print(\"\\n Classification Report: \\n\", classification_report(val_y, xgb_pred3))\n",
    "print(\"Accuracy:\", (accuracy_score(val_y,xgb_pred3)))\n",
    "print(\"AUC Score:\", (roc_auc_score(val_y,y_pred3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2_X = train2_X.drop(['mode','s8', 'time_signature','s6','s2', 's4','s5','s1','key'], axis = 1)\n",
    "val_X = val_X.drop(['mode','s8', 'time_signature','s6','s2', 's4','s5','s1','key'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets train Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfclf = RandomForestClassifier()\n",
    "rfclf.fit(train2_X, train2_y)\n",
    "\n",
    "y_pred = rfclf.predict(val_X)\n",
    "class_pred = rfclf.predict_proba(val_X)[:,1]\n",
    "\n",
    "print('\\n Confusion Matrix:\\n',confusion_matrix(val_y,y_pred))\n",
    "print(\"\\n Classification Report: \\n\", classification_report(val_y, y_pred))\n",
    "print(\"Accuracy:\", (accuracy_score(val_y,y_pred)))\n",
    "print(\"AUC Score:\", (roc_auc_score(val_y,class_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfclf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune hyperparameters to see if we can increase AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfclf2 = RandomForestClassifier(n_estimators=100)\n",
    "rfclf2.fit(train2_X, train2_y)\n",
    "y_pred2 = rfclf2.predict(val_X)\n",
    "class_pred2 = rfclf2.predict_proba(val_X)[:,1]\n",
    "\n",
    "print('\\n Confusion Matrix:\\n',confusion_matrix(val_y,y_pred2))\n",
    "print(\"\\n Classification Report: \\n\", classification_report(val_y, y_pred2))\n",
    "print(\"Accuracy:\", (accuracy_score(val_y,y_pred2)))\n",
    "print(\"AUC Score:\", (roc_auc_score(val_y,class_pred2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble our RF and XGBoost models by averaging probabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## average probabilities of two models\n",
    "\n",
    "# get probabilities of random forest binary classifier\n",
    "x = xgb2.predict_proba(val_X)\n",
    "\n",
    "# get probabilities of SVM binary classifier\n",
    "r = rfclf2.predict_proba(val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add index to probabilities so we can merge\n",
    "x = pd.DataFrame(data=x, index=val_X.index)\n",
    "r = pd.DataFrame(data=r, index=val_X.index)\n",
    "\n",
    "\n",
    "# build a dataframe of probabilities (averaged)\n",
    "P = pd.DataFrame(index=val_X.index)\n",
    "for i in P.index:\n",
    "    try:\n",
    "        P.loc[i,0] = (x.loc[i,0] + r.loc[i,0])/2\n",
    "        P.loc[i,1] = (x.loc[i,1] + r.loc[i,1])/2\n",
    "    except KeyError:\n",
    "        P.loc[i,:] = x.loc[i,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets see if the ensemble increases our AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get new auc score\n",
    "def pred_class(row):\n",
    "    if row[1] > row[0]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "P['pred'] = P.apply(lambda row: pred_class(row), axis =1)\n",
    "new_pred_y = P['pred']\n",
    "\n",
    "print('\\n Confusion Matrix:\\n',confusion_matrix(val_y,new_pred_y))\n",
    "print(\"\\n Classification Report: \\n\", classification_report(val_y, new_pred_y))\n",
    "print(\"Accuracy:\", (accuracy_score(val_y,new_pred_y)))\n",
    "print(\"AUC Score:\", (roc_auc_score(val_y,P[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will write a function that will print out top 10 songs for a user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_songs(user_id):\n",
    "    \n",
    "    # get songs user has listened to \n",
    "    listened_songs = train2_df[train2_df.user_id == user_id].song.unique()\n",
    "    \n",
    "    # get songs user has not listened to \n",
    "    songs = train2_df.drop(columns=['user_id','listen_count']).drop_duplicates('song')\n",
    "    not_listened = songs[~songs.song.isin(listened_songs)].drop(columns=['u1', 'u2', 'u3', 'u4', 'u5', 'u6', 'u7','label'])\n",
    "    not_listened['user_id'] = user_id\n",
    "    \n",
    "    # join user features and song features on songs not listened to\n",
    "    not_listened_df = not_listened.merge(user_factors, on = 'user_id')\n",
    "    \n",
    "    \n",
    "    # add probabilities of belonging to class 'one_plus'\n",
    "    not_listened_df['pred']= P.iloc[:,1]\n",
    "    \n",
    "    # get top 10 predictions\n",
    "    top_pred = not_listened_df.sort_values(by ='pred', ascending=False).head(5)\n",
    "    return top_pred[['song_id', 'song', 'pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_top_songs('f1ccb26d0d49490016747f6592e6f7b1e53a9e54')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2_df[train2_df.user_id == 'f1ccb26d0d49490016747f6592e6f7b1e53a9e54'].sort_values(by='listen_count', ascending=False)[['song','listen_count','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
